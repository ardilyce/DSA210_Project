{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'ChessDataFetcher/1.0 (ardilyuce@gmail.com)'\n",
    "}\n",
    "\n",
    "username = \"ardil30\"  # Chess.com username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archives fetched: 27 archives found.\n",
      "Saving data to ./data/raw/ardil30_raw_games.json...\n",
      "Data saved successfully to ./data/raw/ardil30_raw_games.json. File size: 7609450 bytes\n"
     ]
    }
   ],
   "source": [
    "def fetch_game_archives(username):\n",
    "    \"\"\"\n",
    "    Fetch the game archives URLs for the player.\n",
    "    \"\"\"\n",
    "    url = f'https://api.chess.com/pub/player/{username}/games/archives'\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching archives: HTTP {response.status_code}, {response.text}\")\n",
    "        return []\n",
    "    archives = response.json().get('archives', [])\n",
    "    print(f\"Archives fetched: {len(archives)} archives found.\")\n",
    "    return archives\n",
    "\n",
    "def fetch_games_from_archive(archive_url):\n",
    "    \"\"\"\n",
    "    Fetch all games from a given archive URL.\n",
    "    \"\"\"\n",
    "    response = requests.get(archive_url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching games from {archive_url}: HTTP {response.status_code}, {response.text}\")\n",
    "        return []\n",
    "    games = response.json().get('games', [])\n",
    "    return games\n",
    "\n",
    "def fetch_all_games(username):\n",
    "    \"\"\"\n",
    "    Fetch all games by iterating through their game archives.\n",
    "    \"\"\"\n",
    "    all_games = []\n",
    "    archives = fetch_game_archives(username)\n",
    "    if not archives:\n",
    "        print(\"No archives fetched. Ensure the username is correct or the Chess.com API is accessible.\")\n",
    "        return all_games\n",
    "\n",
    "    for archive_url in archives:\n",
    "        games = fetch_games_from_archive(archive_url)\n",
    "        all_games.extend(games)\n",
    "\n",
    "    return all_games\n",
    "\n",
    "def save_to_json(data, filename):\n",
    "    \"\"\"\n",
    "    Save data to a beautified JSON file.\n",
    "    \"\"\"\n",
    "    print(f\"Saving data to {filename}...\")\n",
    "    if not data:\n",
    "        print(\"No data to save. The file will not be updated.\")\n",
    "        return\n",
    "\n",
    "    with open(filename, \"w\") as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "    print(f\"Data saved successfully to {filename}. File size: {os.path.getsize(filename)} bytes\")\n",
    "\n",
    "# Main code\n",
    "file_path = \"./data/raw/ardil30_raw_games.json\"\n",
    "\n",
    "# Ensure the raw data directory exists\n",
    "os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "# Fetch new games\n",
    "all_games = fetch_all_games(username)\n",
    "\n",
    "# Save fetched data\n",
    "save_to_json(all_games, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_61479/2527713755.py:97: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  return datetime.utcfromtimestamp(unix_time).strftime('%Y-%m-%d %H:%M:%S')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ./data/processed/ardil30_games.json (JSON format)\n",
      "Data saved to ./data/processed/ardil30_games.csv (CSV format)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def load_openings(file_path):\n",
    "    \"\"\"\n",
    "    Load a list of main openings from a text file.\n",
    "    \"\"\"\n",
    "    # Ensure the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        with open(file_path, \"w\") as file:\n",
    "            pass  # Create an empty file\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        return [line.strip().lower() for line in file if line.strip()]\n",
    "\n",
    "def add_opening_to_file(file_path, opening):\n",
    "    \"\"\"\n",
    "    Add a new opening to the openings file if it doesn't already exist.\n",
    "    \"\"\"\n",
    "    openings = load_openings(file_path)\n",
    "    opening_lower = opening.lower()\n",
    "    if opening_lower not in openings:\n",
    "        with open(file_path, \"a\") as file:\n",
    "            file.write(opening + \"\\n\")\n",
    "        print(f\"New opening added to {file_path}: {opening}\")\n",
    "\n",
    "def split_pgn(pgn):\n",
    "    \"\"\"\n",
    "    Split PGN into metadata (headers) and move list.\n",
    "    Format the metadata as a dictionary for better readability.\n",
    "    \"\"\"\n",
    "    if not pgn:\n",
    "        return {\"Information\": {}, \"Moves\": \"No Moves available\"}\n",
    "\n",
    "    try:\n",
    "        parts = pgn.split(\"\\n\\n\")  # Split PGN into headers and moves\n",
    "        metadata_lines = parts[0].strip().split(\"\\n\")  # Split headers by lines\n",
    "        moves = parts[1].strip() if len(parts) > 1 else \"No Moves available\"  # Moves section\n",
    "\n",
    "        # Convert metadata lines to a dictionary\n",
    "        metadata = {}\n",
    "        for line in metadata_lines:\n",
    "            if line.startswith(\"[\") and line.endswith(\"]\"):\n",
    "                key_value = line[1:-1].split(\" \", 1)  # Remove brackets and split by the first space\n",
    "                if len(key_value) == 2:\n",
    "                    key, value = key_value\n",
    "                    metadata[key] = value.strip('\"')  # Remove quotes around values\n",
    "\n",
    "        return {\"Information\": metadata, \"Moves\": moves}\n",
    "    except IndexError:\n",
    "        return {\"Information\": {}, \"Moves\": \"Invalid PGN format\"}\n",
    "\n",
    "def determine_game_result(game, username):\n",
    "    \"\"\"\n",
    "    Determine the result of the game for the given player.\n",
    "    \"\"\"\n",
    "    white_player = game.get(\"white\", {}).get(\"username\", \"\").lower()\n",
    "    black_player = game.get(\"black\", {}).get(\"username\", \"\").lower()\n",
    "    white_result = game.get(\"white\", {}).get(\"result\", \"\").lower()\n",
    "    black_result = game.get(\"black\", {}).get(\"result\", \"\").lower()\n",
    "\n",
    "    if username.lower() == white_player.strip().lower():\n",
    "        if white_result == \"win\":\n",
    "            return \"Win\"\n",
    "        elif white_result in [\"checkmated\", \"timeout\", \"resigned\", \"abandoned\"]:\n",
    "            return \"Loss\"\n",
    "        elif white_result in [\"stalemate\", \"draw\", \"insufficient material\", \"insufficient\", \"repetition\", \"agreed\", \"50move\", \"timevsinsufficient\"]:\n",
    "            return \"Draw\"\n",
    "    elif username.lower() == black_player.strip().lower():\n",
    "        if black_result == \"win\":\n",
    "            return \"Win\"\n",
    "        elif black_result in [\"checkmated\", \"timeout\", \"resigned\", \"abandoned\"]:\n",
    "            return \"Loss\"\n",
    "        elif black_result in [\"stalemate\", \"draw\", \"insufficient material\", \"insufficient\", \"repetition\", \"agreed\", \"50move\", \"timevsinsufficient\"]:\n",
    "            return \"Draw\"\n",
    "    return \"Unknown\"\n",
    "\n",
    "def extract_opening_from_pgn(metadata):\n",
    "    \"\"\"\n",
    "    Extract the opening name from the PGN metadata (based on Chess.com opening URL).\n",
    "    Removes any single quotes from the opening name.\n",
    "    \"\"\"\n",
    "    eco_url = metadata.get(\"ECOUrl\", \"\")\n",
    "    if eco_url and \"chess.com/openings/\" in eco_url:\n",
    "        opening_name = eco_url.split(\"chess.com/openings/\")[-1].replace(\"-\", \" \").capitalize()\n",
    "        opening_name = opening_name.replace(\"'\", \"\")  # Remove any single quotes\n",
    "        return opening_name\n",
    "    return \"Unknown\"\n",
    "\n",
    "def process_game_data(all_games, username, openings_file):\n",
    "    \"\"\"\n",
    "    Beautify and structure game data with main openings and variations.\n",
    "    \"\"\"\n",
    "    def unix_to_readable(unix_time):\n",
    "        return datetime.utcfromtimestamp(unix_time).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Load main openings from the text file\n",
    "    main_openings = load_openings(openings_file)\n",
    "\n",
    "    game_list = []\n",
    "    for game in all_games:\n",
    "        pgn_split = split_pgn(game.get(\"pgn\", \"\"))\n",
    "        metadata = pgn_split.get(\"Information\", {})\n",
    "\n",
    "        # Extract opening name from the ECO URL\n",
    "        opening_name = extract_opening_from_pgn(metadata)\n",
    "\n",
    "        # Determine game result\n",
    "        game_result = determine_game_result(game, username)\n",
    "\n",
    "        # Determine main opening and variation\n",
    "        main_opening = \"Unknown\"\n",
    "        variation = opening_name\n",
    "\n",
    "        for main in main_openings:\n",
    "            if opening_name.lower().find(main.lower()) != -1:  # Compare with main openings\n",
    "                main_opening = main\n",
    "                variation = opening_name.strip().capitalize()\n",
    "                break\n",
    "\n",
    "        # Add unknown opening to the openings file\n",
    "        if main_opening == \"Unknown\" and opening_name != \"Unknown\":\n",
    "            add_opening_to_file(openings_file, opening_name)\n",
    "            main_opening = opening_name\n",
    "            variation = \"Unknown\"\n",
    "\n",
    "        game_entry = {\n",
    "            \"Game URL\": game.get(\"url\", \"\"),\n",
    "            \"Time Class\": game.get(\"time_class\", \"N/A\").capitalize(),\n",
    "            \"End Time\": unix_to_readable(game.get(\"end_time\", 0)),\n",
    "            \"White Player\": game.get(\"white\", {}).get(\"username\", \"Unknown\"),\n",
    "            \"White Rating\": game.get(\"white\", {}).get(\"rating\", \"N/A\"),\n",
    "            \"Black Player\": game.get(\"black\", {}).get(\"username\", \"Unknown\"),\n",
    "            \"Black Rating\": game.get(\"black\", {}).get(\"rating\", \"N/A\"),\n",
    "            \"Result\": game_result,  # Processed as \"Win\", \"Loss\", or \"Draw\"\n",
    "            \"Main Opening\": main_opening,  # Main opening from the text file\n",
    "            \"Variation\": variation,  # Remaining part as variation\n",
    "            \"Information\": pgn_split[\"Information\"],  # Metadata\n",
    "            \"Moves\": pgn_split[\"Moves\"]  # Actual moves\n",
    "        }\n",
    "        if(game.get(\"rules\", {}) == \"chess\"):\n",
    "            game_list.append(game_entry)\n",
    "    return game_list\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    \"\"\"\n",
    "    Save data to a CSV file.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Data saved to {filename} (CSV format)\")\n",
    "\n",
    "def save_to_json(data, filename):\n",
    "    \"\"\"\n",
    "    Save data to a beautified JSON file.\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\") as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "    print(f\"Data saved to {filename} (JSON format)\")\n",
    "\n",
    "# Main code\n",
    "username = \"ardil30\"  # Replace with your Chess.com username\n",
    "raw_file_path = f\"./data/raw/{username}_raw_games.json\"\n",
    "processed_json_path = f\"./data/processed/{username}_games.json\"\n",
    "processed_csv_path = f\"./data/processed/{username}_games.csv\"\n",
    "openings_file_path = \"./data/processed/chess_openings.txt\"\n",
    "\n",
    "# Ensure the processed data directory exists\n",
    "os.makedirs(\"./data/processed\", exist_ok=True)\n",
    "\n",
    "# Load raw data\n",
    "with open(raw_file_path, \"r\") as file:\n",
    "    raw_data = json.load(file)\n",
    "\n",
    "# Process data\n",
    "processed_data = process_game_data(raw_data, username, openings_file_path)\n",
    "\n",
    "# Save processed data\n",
    "save_to_json(processed_data, processed_json_path)\n",
    "save_to_csv(processed_data, processed_csv_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
